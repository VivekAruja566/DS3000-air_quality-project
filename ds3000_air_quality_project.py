# -*- coding: utf-8 -*-
"""DS3000_air_quality_project_.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BJiFcTygdUYocz6FMWc84CUR_yMgpNTF

Setup & Installs

Air Quality Modeling – DS3000 Project
-------------------------------------

This file loads EPA annual air quality data, constructs a site-level dataset,
performs exploratory analysis, and trains both regression and classification
models to predict PM2.5 levels and categorize air quality risk. SHAP is used
for interpreting feature contributions.

Note: This script assumes the EPA annual dataset
'annual_conc_by_monitor_2024.csv' is present in the working directory.
"""

# Setup & Library Imports

# This section imports core libraries for data handling, visualization, preprocessing, model training, evaluation metrics, and SHAP explanations.

# If SHAP not installed in Colab
!pip install shap --quiet

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

# Regression models
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

# Classification models
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier

# Metrics for regression and classification evaluation
from sklearn.metrics import (
    r2_score, mean_absolute_error, mean_squared_error,
    accuracy_score, f1_score, roc_auc_score, classification_report
)

import shap
import warnings
warnings.filterwarnings("ignore")

plt.rcParams["figure.figsize"] = (10, 6)
sns.set(style="whitegrid")

"""#Load the Annual CSV"""

# Loads the Dataset

# This section reads the EPA annual concentration data for 2024. The dataset includes pollutant measurements and weather related variables for each monitoring station across the US.

# Load the raw EPA annual concentrations dataset
DATA_PATH = "annual_conc_by_monitor_2024.csv"

raw = pd.read_csv(DATA_PATH, encoding="latin1") # Latin1 is used to avoid Unicode decoding issues
print(raw.shape)
raw.head()

"""Build site-level dataset (pivot pollutants + weather)"""

# Builds a relevant dataset for analysis

# In this section, only relevant columns are kept for analysis such as common pollutants and weather variables.
# Dataset has been pivoted such that it takes many rows of measurements from the same site year and combines them into a single row. Each pollutant or weather variable has its own column.

# Selects only the relevant fields needed for analysis
cols_needed = [
    "State Name", "County Name", "City Name",
    "Latitude", "Longitude",
    "Year",
    "Parameter Name",
    "Arithmetic Mean"
]
df = raw[cols_needed].copy()

# Choose main pollutants + some weather variables to include
selected_params = [
    "Ozone",
    "PM2.5 - Local Conditions",
    "PM10 - LC",
    "PM10 Total 0-10um STP",
    "Carbon monoxide",
    "Nitrogen dioxide (NO2)",
    "Sulfur dioxide",
    "Relative Humidity ",
    "Outdoor Temperature",
    "Average Ambient Temperature",
    "Average Ambient Pressure",
    "Wind Speed - Resultant",
    "Wind Direction - Resultant"
]

# Keep only the rows for the selected parameters
df_sel = df[df["Parameter Name"].isin(selected_params)].copy()

# Pivot into one row per site/year with each pollutant/weather variable as a column. NaN means that the station does not measure that pollutant/weather variable.
site_df = df_sel.pivot_table(
    index=["State Name", "County Name", "City Name", "Latitude", "Longitude", "Year"],
    columns="Parameter Name",
    values="Arithmetic Mean",
    aggfunc="mean"
).reset_index()

site_df.columns.name = None  # Remove pivot table column group name
print(site_df.shape)
site_df.head()

"""Prepare modeling dataset"""

# Prepares Modeling Dataset

# In this section, PM2.5 is defined as the target variable and the dataset is edited such that rows without PM2.5 measurements have been removed.
# The remaining pollutants, weather variables, and coordinates are used as input features for the models.



TARGET_COL = "PM2.5 - Local Conditions"

# Remove rows without PM2.5 measurements (target variable)
data = site_df.dropna(subset=[TARGET_COL]).copy()

# Feature columns: coordinates + other pollutants/weather (exclude identifiers and target)
feature_cols = [
    c for c in data.columns
    if c not in ["State Name", "County Name", "City Name", "Year", TARGET_COL]
]

numeric_features = feature_cols
categorical_features = ["State Name"] # Use state as the single categorial feature

# Creates a categorical PM2.5 risk label based on quartiles which will be used for the classification task.
data["PM25_Class"] = pd.qcut(
    data[TARGET_COL],
    q=4,
    labels=["Low", "Moderate", "High", "Very High"]
)

print("Data for modeling:", data.shape)
data[[TARGET_COL, "PM25_Class"]].head()

"""Simple EDA (Distributions + Correlations)"""

# In this section, data analysis was performed by visualizing the
# distribution of PM2.5, the class balance of PM2.5 risk categories, and a
# correlation heatmap to understand relationships between pollutant and
# weather features.

# Distribution of PM2.5
sns.histplot(data[TARGET_COL], bins=30, kde=True)
plt.title("Distribution of Annual PM2.5 (Local Conditions)")
plt.xlabel("PM2.5 (µg/m³)")
plt.show()

# Count of PM2.5 classes
sns.countplot(x="PM25_Class", data=data, order=["Low","Moderate","High","Very High"])
plt.title("PM2.5 Risk Classes (Quartiles)")
plt.show()

# Correlation heatmap for numeric pollutants + weather
corr_cols = [
    c for c in data.columns
    if c not in ["State Name", "County Name", "City Name", "Year", "PM25_Class"]
]
corr = data[corr_cols].corr()

plt.figure(figsize=(12, 8))
sns.heatmap(corr, annot=False, cmap="coolwarm")
plt.title("Correlation Heatmap: Pollutants and Weather Variables")
plt.show()

"""Preprocessing pipelines (Shared by Regression + Classification)"""

# In this section, we split the data into training and test sets, define numeric
# (median imputation and scaling) and categorical (imputation and one-hot encoding)
# preprocessing steps, and combine them into a reusable ColumnTransformer.

# The ColumnTransformer applies the appropriate preprocessing steps to each
# feature type (numeric or categorical) and combines them into a single
# transformed dataset for model training.


# Split into X, y for regression
X_reg = data[feature_cols + categorical_features]
y_reg = data[TARGET_COL]

X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(
    X_reg, y_reg, test_size=0.2, random_state=42
)

# Preprocessing: impute + scale numeric; impute + one-hot encode categorical
numeric_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])

# Categorical: impute + onehot encode
categorical_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(handle_unknown="ignore"))
])

# Combine preprocessing steps
preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numeric_features),
        ("cat", categorical_transformer, categorical_features)
    ]
)

"""Regression models (Linear, Random Forest, Gradient Boosting)"""

# In this section, we build pipelines that apply preprocessing and then train
# three regression models (Linear Regression, Random Forest, and Gradient
# Boosting) and evaluate their performance using R², MAE, and RMSE.

reg_models = {
    "Linear Regression": LinearRegression(),
    "Random Forest": RandomForestRegressor(n_estimators=200, random_state=42),
    "Gradient Boosting": GradientBoostingRegressor(random_state=42)
}

reg_results = {}

# Train and evaluate each regression model
for name, model in reg_models.items():
    pipe = Pipeline(steps=[
        ("preprocess", preprocessor),
        ("model", model)
    ])
    pipe.fit(X_train_reg, y_train_reg)
    preds = pipe.predict(X_test_reg)

    # Compute regression metrics
    r2 = r2_score(y_test_reg, preds)
    mae = mean_absolute_error(y_test_reg, preds)
    rmse = np.sqrt(mean_squared_error(y_test_reg, preds))

    reg_results[name] = {"R2": r2, "MAE": mae, "RMSE": rmse}

# Show results in table form
pd.DataFrame(reg_results).T

"""Classification models (LogReg, SVM, Neural Network)"""

# In this section, we train three classification models (Logistic Regression,
# SVM with an RBF kernel, and a Neural Network) using PM2.5 quartile classes as
# the target and evaluate their performance using Accuracy, weighted F1-score,
# and multiclass AUC (one-vs-rest).

# Prepare classification dataset
X_clf = data[feature_cols + categorical_features]
y_clf = data["PM25_Class"]

X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(
    X_clf, y_clf, test_size=0.2, random_state=42, stratify=y_clf
)

clf_models = {
    "Logistic Regression": LogisticRegression(max_iter=500, multi_class="multinomial"),
    "SVM": SVC(kernel="rbf", probability=True),
    "Neural Network": MLPClassifier(hidden_layer_sizes=(64, 32),
                                    max_iter=500, random_state=42)
}

# LabelEncoder needed for multiclass AUC
le = LabelEncoder()
le.fit(y_clf)

clf_results = {}

# Train and evaluate each classifier
for name, model in clf_models.items():
    pipe = Pipeline(steps=[
        ("preprocess", preprocessor),
        ("model", model)
    ])
    pipe.fit(X_train_clf, y_train_clf)

    preds = pipe.predict(X_test_clf)
    probs = pipe.predict_proba(X_test_clf)

    # Compute classification metrics
    acc = accuracy_score(y_test_clf, preds)
    f1 = f1_score(y_test_clf, preds, average="weighted")
    # AUC (multi-class, one-vs-rest)
    auc = roc_auc_score(le.transform(y_test_clf),
                        probs, multi_class="ovr")

    clf_results[name] = {"Accuracy": acc, "F1_weighted": f1, "AUC_ovr": auc}

    print(f"\n=== {name} ===")
    print(classification_report(y_test_clf, preds))

# Display results
pd.DataFrame(clf_results).T

"""*SHAP* feature importance (Random Forest regression)"""

# In this section, we refit the preprocessing pipeline and Random Forest model,
# generate full feature names (numeric and one-hot encoded), and use SHAP’s
# TreeExplainer to compute feature importance and visualize each feature’s
# impact on PM2.5 predictions using a beeswarm plot.

from scipy import sparse
import pandas as pd

# Fit the preprocessor and transform X
X_train_reg_proc = preprocessor.fit_transform(X_train_reg)

# If it's a sparse matrix, make it dense
if sparse.issparse(X_train_reg_proc):
    X_train_reg_proc = X_train_reg_proc.toarray()

# Ensure float dtype (no objects)
X_train_reg_proc = X_train_reg_proc.astype(float)

# Fit the RF model on the processed numeric data
rf_model = RandomForestRegressor(n_estimators=200, random_state=42)
rf_model.fit(X_train_reg_proc, y_train_reg)

# Build list of feature names after preprocessing
num_names = numeric_features

cat_ohe_names = list(
    preprocessor.named_transformers_["cat"]
    .named_steps["onehot"]
    .get_feature_names_out(categorical_features)
)

feature_names = num_names + cat_ohe_names

# Wrap processed data in a DataFrame with column names
X_shap = pd.DataFrame(X_train_reg_proc, columns=feature_names)

# Run SHAP analysis using the DataFrame
explainer = shap.TreeExplainer(rf_model)
shap_values = explainer(X_shap)

# Beeswarm plot will now use your actual feature names
shap.plots.beeswarm(shap_values, max_display=15, show=False)
plt.title("SHAP Feature Importance – Random Forest (PM2.5 Regression)")
plt.xlabel("SHAP value (impact on model output)")
plt.show()

"""#**Project Summary**

## **1. Overview**
This project analyzes the annual site level air quality data from the EPA’s  
`annual_conc_by_monitor_2024.csv` dataset.  
We prepared a clean pollutant + weather dataset, explored relationships, and trained both regression and classification models to understand and predict PM2.5 levels.

---

## **2. Regression Models (Predicting PM2.5 Numeric Value)**

Three regression models are evaluated:

- **Linear Regression** – interpretable baseline model  
- **Random Forest Regressor** – handles non linear relationships & interactions  
- **Gradient Boosting Regressor** – strong performance on tabular data

**Observations:**

- Random Forest / Gradient Boosting produced the **highest R²**  
- Linear Regression has the **lowest error** when data is roughly linear  
- Weather features (temperature, humidity) improved accuracy across all models

---

## **3. Classification Models (PM2.5 Risk Categories)**

We created four PM2.5 risk classes using quartiles:  
**Low, Moderate, High, Very High**

Models evaluated:

- **Logistic Regression** – simple and interpretable baseline  
- **SVM (RBF Kernel)** – strong non linear boundary classifier  
- **Neural Network (MLP)** – learns complex multi feature interactions

**Observations:**

- SVM and Neural Network usually achieve the **highest Accuracy and F1-score**  
- Logistic Regression performs well but struggles when classes overlap  
- Weather features help classification separation

---

## **4. Feature Importance (SHAP)**

Using SHAP on the Random Forest regression model:

The top contributing factors leading to higher PM2.5 include:

- Longitude
- Outdoor Temperature
- PM10 Total 0-10µm STP
- Latitude
- Average Ambient Temperature
- Nitrogen Dioxide (NO₂)

**Interpretation:**  
Pollution levels and weather dynamics interact strongly to determine PM2.5 concentration.

---

## **5. Key Insights**

- PM2.5 is strongly correlated with Longitude, Outdoor Temperature, PM10, Latitude, Average Ambient Temperature, and Nitrogen Dioxide.
- Random Forest and Gradient Boosting provide the most reliable PM2.5 predictions because they capture complex nonlinear relationships between pollutants, weather conditions, and geographic features, resulting in the highest R² scores and lowest error across all regression models.  
- SVM and Neural Networks produce the best classifications of PM2.5 risk levels because they are better at learning nonlinear class boundaries, allowing them to separate Low, Moderate, High, and Very High PM2.5 categories with superior Accuracy, weighted F1-score, and AUC.  
- SHAP analysis confirms that both pollutants and meteorological factors influence air quality because the top contributing features include geographic location, PM10, and temperature variables.  

---

## **6. Conclusion**

This modeling pipeline demonstrates:

- High predictive capability for **regression (PM2.5 numeric)**  
- Strong performance in **classification (risk levels)**  
- Clear environmental insight through **feature importance analysis**

This framework can be used for future environmental modeling, risk alerts, and air quality forecasting systems.

"""